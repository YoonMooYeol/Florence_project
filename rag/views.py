from rest_framework.views import APIView
from rest_framework.response import Response
from rest_framework import status
from rest_framework.parsers import JSONParser
from .method import RAGProcessor, RAGQuery, RDFProcessor
from .models import RAG_DB
from dotenv import load_dotenv
import os
from tqdm import tqdm
import json
import time
import glob
import rdflib
from rdflib import URIRef

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# RAGProcessorì—ì„œ ì •ì˜ëœ ê²½ë¡œ ì‚¬ìš©
DB_DIR = RAGProcessor.DB_DIR
CSV_PATTERN = "data/rag/*.csv"

# DB_DIRì´ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
if not os.path.exists(DB_DIR):
    os.makedirs(DB_DIR, exist_ok=True)

class RAGQueryView(APIView):
    """
    RAG ì‹œìŠ¤í…œì— ì§ˆì˜í•˜ëŠ” API ë·°
    
    Endpoints:
        GET /rag/query/: API ì‚¬ìš© ë°©ë²• ë°˜í™˜
        POST /rag/query/: RAG ì‹œìŠ¤í…œì— ì§ˆì˜
    """
    parser_classes = (JSONParser,)
    permission_classes = []  # ì¸ì¦ ë¹„í™œì„±í™”
    
    def get(self, request):
        """API ì‚¬ìš© ë°©ë²•ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return Response({
            'message': 'RAG ì¿¼ë¦¬ API',
            'usage': {
                'method': 'POST',
                'description': 'RAG ì‹œìŠ¤í…œì— ì§ˆì˜í•©ë‹ˆë‹¤.',
                'endpoint': '/v1/rag/query/',
                'parameters': {
                    'query': '(í•„ìˆ˜) ì¿¼ë¦¬ í…ìŠ¤íŠ¸',
                    'max_tokens': '(ì„ íƒ) ì‘ë‹µ ìµœëŒ€ í† í° ìˆ˜',
                    'use_maternal_health': '(ì„ íƒ) ì‚°ëª¨ ê±´ê°• ë°ì´í„° ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: true)'
                }
            }
        }, status=status.HTTP_200_OK)
    
    def post(self, request):
        """RAG ì‹œìŠ¤í…œì— ì§ˆì˜í•©ë‹ˆë‹¤. ëª¨ë“  ì§ˆë¬¸ì€ ì‚°ëª¨ê°€ í•˜ëŠ” ê²ƒìœ¼ë¡œ ê°„ì£¼í•©ë‹ˆë‹¤."""
        try:
            query = request.data.get('query')
            max_tokens = request.data.get('max_tokens', 150)
            use_maternal_health = request.data.get('use_maternal_health', True)  # ê¸°ë³¸ê°’ì„ Trueë¡œ ë³€ê²½
            
            if not query:
                return Response({
                    'error': 'ì¿¼ë¦¬ê°€ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # ëª¨ë“  ì§ˆë¬¸ì„ ì‚°ëª¨ ê±´ê°• ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ì²˜ë¦¬
            retriever, chain = RAGQuery.create_maternal_health_qa_chain()
            retrieved_docs = retriever.invoke(query)
            retrieved_context = "\n".join([doc.page_content for doc in retrieved_docs])
            result = chain.invoke({
                "retrieved_context": retrieved_context,
                "question": query
            }).content
            
            return Response({
                'message': 'RAG ì¿¼ë¦¬ ì™„ë£Œ',
                'query': query,
                'result': result
            }, status=status.HTTP_200_OK)
            
        except Exception as e:
            return Response({
                'error': f'Error code: {e.__class__.__name__} - {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

class RAGAutoEmbedView(APIView):
    """
    data í´ë”ì˜ ëª¨ë“  íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì„ë² ë”©í•˜ëŠ” API ë·°
    
    Endpoints:
        GET /rag/auto-embed/: API ì‚¬ìš© ë°©ë²• ë°˜í™˜
        POST /rag/auto-embed/: ëª¨ë“  ë°ì´í„° íŒŒì¼ ìë™ ì„ë² ë”©
    """
    permission_classes = []  # ì¸ì¦ ë¹„í™œì„±í™”
    
    def get(self, request):
        """API ì‚¬ìš© ë°©ë²•ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return Response({
            'message': 'ìë™ ì„ë² ë”© API',
            'usage': {
                'method': 'POST',
                'description': 'data í´ë”ì˜ ëª¨ë“  íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì„ë² ë”©í•©ë‹ˆë‹¤.',
                'endpoint': '/v1/rag/auto-embed/',
                'parameters': {
                    'data_dir': '(ì„ íƒ) ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ. ê¸°ë³¸ê°’ì€ "data"',
                    'file_types': '(ì„ íƒ) ì²˜ë¦¬í•  íŒŒì¼ ìœ í˜• ëª©ë¡. ê¸°ë³¸ê°’ì€ ["csv", "json", "rdf", "xml"]',
                    'force_reprocess': '(ì„ íƒ) ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ë„ ë‹¤ì‹œ ì²˜ë¦¬í• ì§€ ì—¬ë¶€. ê¸°ë³¸ê°’ì€ false'
                }
            }
        }, status=status.HTTP_200_OK)
    
    def post(self, request):
        """ëª¨ë“  ë°ì´í„° íŒŒì¼ì„ ìë™ìœ¼ë¡œ ì„ë² ë”©í•©ë‹ˆë‹¤."""
        try:
            data_dir = request.data.get('data_dir', 'data')
            file_types = request.data.get('file_types', ['csv', 'json', 'rdf', 'xml'])
            force_reprocess = request.data.get('force_reprocess', False)
            
            # ê²°ê³¼ ì €ì¥ ë³€ìˆ˜
            results = {
                'total_files_found': 0,
                'new_files_processed': 0,
                'skipped_files': 0,
                'failed_files': 0,
                'total_documents_embedded': 0,
                'processing_time': 0,
                'file_details': []
            }
            
            # ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡ ìƒì„±
            all_files = []
            for file_type in file_types:
                file_pattern = os.path.join(data_dir, f"**/*.{file_type}")
                files = glob.glob(file_pattern, recursive=True)
                for file in files:
                    all_files.append((file, file_type))
            
            results['total_files_found'] = len(all_files)
            
            # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            processed_files = set(RAG_DB.objects.values_list('file_path', flat=True))
            
            # ì‹œì‘ ì‹œê°„ ê¸°ë¡
            start_time = time.time()
            
            # íŒŒì¼ ì²˜ë¦¬
            with tqdm(total=len(all_files), desc="ğŸ“‚ ì „ì²´ íŒŒì¼ ì§„í–‰ë¥ ") as pbar:
                # ì´ˆê¸° ì§„í–‰ë¥  ë©”ì‹œì§€ ì„¤ì •
                pbar.set_postfix_str(f"ì²˜ë¦¬: 0ê°œ, ìŠ¤í‚µ: 0ê°œ")
                
                for file_path, file_type in all_files:
                    file_result = {
                        'file_path': file_path,
                        'file_type': file_type,
                        'status': '',
                        'documents_embedded': 0
                    }
                    
                    try:
                        # ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì¸ì§€ í™•ì¸
                        if file_path in processed_files and not force_reprocess:
                            file_result['status'] = 'skipped (already processed)'
                            results['skipped_files'] += 1
                            results['file_details'].append(file_result)
                            pbar.update(1)
                            # ìŠ¤í‚µëœ íŒŒì¼ í‘œì‹œ
                            pbar.set_postfix_str(f"ì²˜ë¦¬: {results['new_files_processed']}ê°œ, ìŠ¤í‚µ: {results['skipped_files']}ê°œ")
                            continue
                        
                        # force_reprocess=trueì´ê³  ì´ë¯¸ ì²˜ë¦¬ëœ íŒŒì¼ì¸ ê²½ìš°, ê¸°ì¡´ ë ˆì½”ë“œ ì‚­ì œ
                        if file_path in processed_files and force_reprocess:
                            RAG_DB.objects.filter(file_path=file_path).delete()
                        
                        # íŒŒì¼ í™•ì¥ì í™•ì¸
                        file_ext = os.path.splitext(file_path)[1].lower()
                        
                        # íŒŒì¼ ì´ë¦„ì—ì„œ ê±´ê°• ê´€ë ¨ í‚¤ì›Œë“œ í™•ì¸
                        file_name = os.path.basename(file_path).lower()
                        health_keywords = ['health', 'medical', 'wellness', 'ê±´ê°•', 'ì˜ë£Œ', 'ì›°ë‹ˆìŠ¤', 'ì‚°ëª¨', 'ì„ì‹ ', 'ì¶œì‚°', 'maternal', 'pregnancy']
                        is_health_related = any(keyword in file_name for keyword in health_keywords)
                        
                        if file_ext == '.csv':
                            # CSV íŒŒì¼ ì²˜ë¦¬
                            vectorstore, existing_ids = RAGProcessor.initialize_chroma_db()
                            
                            # CSV íŒŒì¼ ë¡œë“œ ë° ë©”íƒ€ë°ì´í„° ì¶”ê°€
                            docs = RAGProcessor.load_csv_with_metadata(file_path)
                            if not docs:
                                raise ValueError("CSV íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            
                            # ìƒˆ ë¬¸ì„œ í•„í„°ë§
                            new_docs = RAGProcessor.filter_new_documents(docs, existing_ids, file_path)
                            
                            # ë¬¸ì„œ ë¶„í• 
                            splits = RAGProcessor.split_documents(new_docs)
                            
                            # ë°ì´í„° ì¤€ë¹„
                            texts, metadatas, ids = RAGProcessor.prepare_data_for_chroma(splits)
                            
                            # ì„ë² ë”© ìƒì„±
                            embeddings = RAGProcessor.create_embeddings(texts)
                            
                            # Chroma DB ì—…ë°ì´íŠ¸
                            RAGProcessor.update_chroma_db(
                                vectorstore, texts, embeddings, metadatas, ids, DB_DIR
                            )
                            
                            # ì²˜ë¦¬ ì™„ë£Œ ê¸°ë¡
                            RAG_DB.objects.create(file_name=os.path.basename(file_path), file_path=file_path)
                            
                            file_result['status'] = 'success'
                            file_result['documents_embedded'] = len(new_docs)
                            results['total_documents_embedded'] += len(new_docs)
                            
                        elif file_ext == '.json':
                            # JSON íŒŒì¼ ì²˜ë¦¬
                            with open(file_path, "r", encoding="utf-8") as f:
                                file_content = f.read()
                            
                            try:
                                conversation = json.loads(file_content)
                            except Exception as e:
                                raise ValueError(f"ìœ íš¨í•˜ì§€ ì•Šì€ JSON íŒŒì¼: {str(e)}")
                            
                            # í•„ìˆ˜ í‚¤ ì²´í¬: infoì™€ utterances í•„ìš”
                            if not {"info", "utterances"}.issubset(conversation.keys()):
                                raise ValueError("JSON íŒŒì¼ì€ infoì™€ utterances í‚¤ë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤.")
                            
                            # Chroma DB ì´ˆê¸°í™”
                            vectorstore, existing_ids = RAGProcessor.initialize_chroma_db()
                            
                            # JSON íŒŒì¼ ì²˜ë¦¬
                            vectorstore, new_docs, count = RAGProcessor.process_conversation_json(
                                conversation, existing_ids, vectorstore
                            )
                            
                            # ì²˜ë¦¬ ì™„ë£Œ ê¸°ë¡
                            RAG_DB.objects.create(file_name=os.path.basename(file_path), file_path=file_path)
                            
                            file_result['status'] = 'success'
                            file_result['documents_embedded'] = new_docs
                            results['total_documents_embedded'] += new_docs
                            
                        elif file_ext in ['.rdf', '.xml', '.n-triples', '.nt']:
                            # RDF íŒŒì¼ ì²˜ë¦¬
                            # ê±´ê°• ê´€ë ¨ íŒŒì¼ì¸ ê²½ìš° ì‚°ëª¨ ê±´ê°• ë°ì´í„° ì²˜ë¦¬ ë°©ì‹ ì‚¬ìš©
                            if is_health_related:
                                print(f"ê±´ê°• ê´€ë ¨ ë°ì´í„°ë¡œ ì²˜ë¦¬: {file_path}")
                                # n-triples íŒŒì¼ì¸ ê²½ìš° ì§ì ‘ íŒŒì‹± ë°©ì‹ ì‚¬ìš©
                                if file_ext in ['.n-triples', '.nt']:
                                    result = RAGProcessor.embed_maternal_health_data_from_ntriples(file_path, format='nt')
                                else:
                                    result = RAGProcessor.embed_maternal_health_data(file_path)
                            else:
                                # ì¼ë°˜ RDF íŒŒì¼ ì²˜ë¦¬
                                result = RAGProcessor.process_rdf_data(file_path)
                            
                            # ì²˜ë¦¬ ì™„ë£Œ ê¸°ë¡
                            RAG_DB.objects.create(file_name=os.path.basename(file_path), file_path=file_path)
                            
                            file_result['status'] = 'success'
                            file_result['documents_embedded'] = result.get('embedded_resources', 0)
                            results['total_documents_embedded'] += result.get('embedded_resources', 0)
                        
                        results['new_files_processed'] += 1
                        # ì²˜ë¦¬ëœ íŒŒì¼ ìˆ˜ í‘œì‹œ
                        pbar.set_postfix_str(f"ì²˜ë¦¬: {results['new_files_processed']}ê°œ, ìŠ¤í‚µ: {results['skipped_files']}ê°œ")
                        
                    except Exception as e:
                        file_result['status'] = 'failed'
                        file_result['error'] = str(e)
                        results['failed_files'] += 1
                        # ì‹¤íŒ¨í•œ íŒŒì¼ í‘œì‹œ
                        pbar.set_postfix_str(f"ì²˜ë¦¬: {results['new_files_processed']}ê°œ, ìŠ¤í‚µ: {results['skipped_files']}ê°œ, ì‹¤íŒ¨: {results['failed_files']}ê°œ")
                    
                    results['file_details'].append(file_result)
                    pbar.update(1)
            
            # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
            end_time = time.time()
            results['processing_time'] = round(end_time - start_time, 2)
            
            # ê²°ê³¼ ìš”ì•½ ìƒì„±
            summary = {
                'message': 'ìë™ ì„ë² ë”© ì™„ë£Œ',
                'total_files_found': results['total_files_found'],
                'new_files_processed': results['new_files_processed'],
                'skipped_files': results['skipped_files'],
                'failed_files': results['failed_files'],
                'total_documents_embedded': results['total_documents_embedded'],
                'processing_time_seconds': results['processing_time'],
                'file_details': results['file_details']
            }
            
            return Response(summary, status=status.HTTP_200_OK)
            
        except Exception as e:
            return Response({
                'error': str(e)
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

class RDFQueryView(APIView):
    """
    RDF ë°ì´í„°ì— ì§ì ‘ SPARQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ëŠ” API ë·°
    
    Endpoints:
        GET /rag/rdf-query/: API ì‚¬ìš© ë°©ë²• ë°˜í™˜
        POST /rag/rdf-query/: RDF ë°ì´í„°ì— SPARQL ì¿¼ë¦¬ ì‹¤í–‰
    """
    parser_classes = (JSONParser,)
    permission_classes = []  # ì¸ì¦ ë¹„í™œì„±í™”
    
    def get(self, request):
        """API ì‚¬ìš© ë°©ë²•ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return Response({
            'message': 'RDF ì¿¼ë¦¬ API',
            'usage': {
                'method': 'POST',
                'description': 'RDF ë°ì´í„°ì— SPARQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.',
                'endpoint': '/v1/rag/rdf-query/',
                'parameters': {
                    'query': '(í•„ìˆ˜) SPARQL ì¿¼ë¦¬ ë¬¸ìì—´',
                    'rdf_file': '(ì„ íƒ) ì¿¼ë¦¬í•  RDF íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: data/rdf/wellness.rdf)',
                    'format': '(ì„ íƒ) RDF íŒŒì¼ í˜•ì‹ (ê¸°ë³¸ê°’: xml)',
                    'resource_uri': '(ì„ íƒ) íŠ¹ì • ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ëª¨ë“  ì •ë³´ë¥¼ ì¡°íšŒí•  ê²½ìš° ë¦¬ì†ŒìŠ¤ URI'
                },
                'examples': {
                    'basic_query': {
                        'query': 'SELECT ?s ?p ?o WHERE { ?s ?p ?o } LIMIT 10'
                    },
                    'resource_info': {
                        'resource_uri': 'http://www.wellness.ai/resource/29-222'
                    }
                }
            }
        }, status=status.HTTP_200_OK)
    
    def post(self, request):
        """RDF ë°ì´í„°ì— SPARQL ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤."""
        try:
            # ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ ë° í˜•ì‹ ì„¤ì •
            rdf_file = request.data.get('rdf_file', 'data/rdf/wellness.rdf')
            format = request.data.get('format', 'xml')
            
            # RDF í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
            processor = RDFProcessor(rdf_file, format)
            
            # ë¦¬ì†ŒìŠ¤ URIê°€ ì œê³µëœ ê²½ìš° í•´ë‹¹ ë¦¬ì†ŒìŠ¤ ì •ë³´ ë°˜í™˜
            resource_uri = request.data.get('resource_uri')
            if resource_uri:
                # ë¦¬ì†ŒìŠ¤ ì •ë³´ ì¡°íšŒ
                resource_info = processor.get_resource_info(resource_uri)
                
                # ë¼ë²¨ ì •ë³´ ì¶”ê°€
                label = processor.get_label(resource_uri)
                
                # ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ê°€ê³µ
                formatted_result = {
                    'uri': resource_uri,
                    'label': label,
                    'properties': {}
                }
                
                # ì†ì„± ì •ë³´ ì²˜ë¦¬
                for pred, values in resource_info.items():
                    pred_label = processor.get_label(pred) or (pred.split('/')[-1] if pred else 'unknown')
                    formatted_values = []
                    
                    for value in values:
                        if isinstance(value, str) and value.startswith('http'):
                            value_label = processor.get_label(value)
                            formatted_values.append({
                                'uri': value,
                                'label': value_label
                            })
                        else:
                            formatted_values.append(value)
                    
                    formatted_result['properties'][pred_label] = formatted_values
                
                # ì¶”ê°€ë¡œ Turtle í˜•ì‹ì˜ ê²°ê³¼ë„ ì œê³µ
                g = rdflib.Graph()
                g.parse(rdf_file, format=format)
                
                subject = URIRef(resource_uri)
                subgraph = rdflib.Graph()
                for s, p, o in g.triples((subject, None, None)):
                    subgraph.add((s, p, o))
                
                turtle_format = subgraph.serialize(format="turtle")
                
                return Response({
                    'resource_info': formatted_result,
                    'turtle_format': turtle_format,
                    'triples_count': len(list(subgraph))
                }, status=status.HTTP_200_OK)
            
            # SPARQL ì¿¼ë¦¬ê°€ ì œê³µëœ ê²½ìš° ì¿¼ë¦¬ ì‹¤í–‰
            query = request.data.get('query')
            if not query:
                return Response({
                    'error': 'SPARQL ì¿¼ë¦¬ ë˜ëŠ” ë¦¬ì†ŒìŠ¤ URIê°€ í•„ìš”í•©ë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # ì¿¼ë¦¬ ì‹¤í–‰
            results = processor.execute_query(query)
            
            # ê²°ê³¼ ì¹´ìš´íŠ¸ ì¶”ê°€
            results_count = len(results)
            
            return Response({
                'results': results,
                'count': results_count,
                'query': query
            }, status=status.HTTP_200_OK)
            
        except Exception as e:
            import traceback
            return Response({
                'error': str(e),
                'traceback': traceback.format_exc()
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

class RDFAnalysisView(APIView):
    """
    RDF ì¿¼ë¦¬ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  í™œìš©í•˜ëŠ” API ë·°
    
    Endpoints:
        GET /rag/rdf-analysis/: API ì‚¬ìš© ë°©ë²• ë°˜í™˜
        POST /rag/rdf-analysis/: RDF ë°ì´í„° ë¶„ì„ ë° í™œìš©
    """
    parser_classes = (JSONParser,)
    permission_classes = []  # ì¸ì¦ ë¹„í™œì„±í™”
    
    def get(self, request):
        """API ì‚¬ìš© ë°©ë²•ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        return Response({
            'message': 'RDF ë°ì´í„° ë¶„ì„ API',
            'usage': {
                'method': 'POST',
                'description': 'RDF ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  í™œìš©í•©ë‹ˆë‹¤.',
                'endpoint': '/v1/rag/rdf-analysis/',
                'parameters': {
                    'action': '(í•„ìˆ˜) ìˆ˜í–‰í•  ë¶„ì„ ì‘ì—… ì¢…ë¥˜ (resource_relations, keyword_search, category_stats, resource_summary)',
                    'rdf_file': '(ì„ íƒ) ë¶„ì„í•  RDF íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: data/rdf/wellness.n-triples)',
                    'format': '(ì„ íƒ) RDF íŒŒì¼ í˜•ì‹ (ê¸°ë³¸ê°’: nt)',
                    'resource_uri': '(ì¡°ê±´ë¶€ í•„ìˆ˜) actionì´ resource_relations, resource_summaryì¸ ê²½ìš° í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ URI',
                    'keyword': '(ì¡°ê±´ë¶€ í•„ìˆ˜) actionì´ keyword_searchì¸ ê²½ìš° í•„ìš”í•œ ê²€ìƒ‰ í‚¤ì›Œë“œ',
                    'category': '(ì¡°ê±´ë¶€ í•„ìˆ˜) actionì´ category_statsì¸ ê²½ìš° í•„ìš”í•œ ì¹´í…Œê³ ë¦¬(íƒ€ì…) URI',
                    'depth': '(ì„ íƒ) ê´€ê³„ íƒìƒ‰ ê¹Šì´ (ê¸°ë³¸ê°’: 1)'
                },
                'examples': {
                    'resource_relations': {
                        'action': 'resource_relations',
                        'resource_uri': 'http://www.wellness.ai/resource/02-016',
                        'depth': 2
                    },
                    'keyword_search': {
                        'action': 'keyword_search',
                        'keyword': 'ì„ì‹ '
                    },
                    'category_stats': {
                        'action': 'category_stats',
                        'category': 'http://www.wellness.ai/schema/class/Disease'
                    },
                    'resource_summary': {
                        'action': 'resource_summary',
                        'resource_uri': 'http://www.wellness.ai/resource/02-016'
                    }
                }
            }
        }, status=status.HTTP_200_OK)
    
    def post(self, request):
        """RDF ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  í™œìš©í•©ë‹ˆë‹¤."""
        try:
            # ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì„¤ì •
            action = request.data.get('action')
            rdf_file = request.data.get('rdf_file', 'data/rdf/wellness.n-triples')
            format = request.data.get('format', 'nt')
            
            if not action:
                return Response({
                    'error': 'ë¶„ì„ ì‘ì—… ì¢…ë¥˜(action)ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.'
                }, status=status.HTTP_400_BAD_REQUEST)
            
            # RDF í”„ë¡œì„¸ì„œ ì´ˆê¸°í™”
            processor = RDFProcessor(rdf_file, format)
            
            # ì‘ì—… ì¢…ë¥˜ì— ë”°ë¼ ë¶„ì„ ìˆ˜í–‰
            if action == 'resource_relations':
                return self._analyze_resource_relations(request, processor)
            elif action == 'keyword_search':
                return self._analyze_keyword_search(request, processor)
            elif action == 'category_stats':
                return self._analyze_category_stats(request, processor)
            elif action == 'resource_summary':
                return self._analyze_resource_summary(request, processor)
            else:
                return Response({
                    'error': f'ì§€ì›í•˜ì§€ ì•ŠëŠ” ë¶„ì„ ì‘ì—…ì…ë‹ˆë‹¤: {action}'
                }, status=status.HTTP_400_BAD_REQUEST)
                
        except Exception as e:
            import traceback
            return Response({
                'error': str(e),
                'traceback': traceback.format_exc()
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)
    
    def _analyze_resource_relations(self, request, processor):
        """ë¦¬ì†ŒìŠ¤ì˜ ê´€ê³„ ë„¤íŠ¸ì›Œí¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
        resource_uri = request.data.get('resource_uri')
        depth = int(request.data.get('depth', 1))
        
        if not resource_uri:
            return Response({
                'error': 'resource_uriê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }, status=status.HTTP_400_BAD_REQUEST)
        
        # ë¦¬ì†ŒìŠ¤ ë¼ë²¨ ì¡°íšŒ
        resource_label = processor.get_label(resource_uri) or resource_uri.split('/')[-1]
        
        # ê´€ê³„ ë„¤íŠ¸ì›Œí¬ êµ¬ì¶•
        network = self._build_relation_network(processor, resource_uri, depth)
        
        # ì •ë ¬ëœ ê´€ê³„ ê·¸ë£¹ ìƒì„±
        relation_groups = {}
        for relation in network:
            rel_type = relation['relation_type']
            if rel_type not in relation_groups:
                relation_groups[rel_type] = []
            relation_groups[rel_type].append(relation)
        
        return Response({
            'resource_uri': resource_uri,
            'resource_label': resource_label,
            'relations_count': len(network),
            'relation_groups': relation_groups,
            'depth': depth
        }, status=status.HTTP_200_OK)
    
    def _build_relation_network(self, processor, resource_uri, depth=1, visited=None):
        """ë¦¬ì†ŒìŠ¤ì˜ ê´€ê³„ ë„¤íŠ¸ì›Œí¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ êµ¬ì¶•í•©ë‹ˆë‹¤."""
        if visited is None:
            visited = set()
        
        if resource_uri in visited or depth <= 0:
            return []
        
        visited.add(resource_uri)
        relations = []
        
        # ì£¼ì–´ì§„ ë¦¬ì†ŒìŠ¤ê°€ ì£¼ì–´ì¸ íŠ¸ë¦¬í”Œ íƒìƒ‰
        query = f"""
        SELECT ?p ?o WHERE {{
            <{resource_uri}> ?p ?o .
            FILTER(?p != <http://www.w3.org/1999/02/22-rdf-syntax-ns#type>)
            FILTER(?p != <http://www.wellness.ai/resource>)
        }}
        """
        print(f"[DEBUG] ì¿¼ë¦¬ ì‹¤í–‰: {query}")
        
        # ì§ì ‘ RDF ê·¸ë˜í”„ì—ì„œ íŠ¸ë¦¬í”Œ ì¡°íšŒ
        resource = rdflib.URIRef(resource_uri)
        
        # íŠ¸ë¦¬í”Œ ì§ì ‘ ì¡°íšŒ
        for s, p, o in processor.graph.triples((resource, None, None)):
            # typeê³¼ resource ì†ì„±ì€ ì œì™¸
            if p == rdflib.RDF.type or str(p) == "http://www.wellness.ai/resource":
                continue
                
            pred = str(p)
            
            # URIì¸ ê²½ìš°ì—ë§Œ ë¼ë²¨ ì¡°íšŒ
            is_uri = isinstance(o, rdflib.URIRef)
            obj = str(o) if is_uri else o.value if isinstance(o, rdflib.Literal) else str(o)
            
            obj_label = processor.get_label(obj) if is_uri else obj
            pred_label = processor.get_label(pred) or (pred.split('/')[-1] if pred else 'unknown')
            
            print(f"[DEBUG] ë¼ë²¨ ì •ë³´: pred_label={pred_label}, obj_label={obj_label}, is_uri={is_uri}")
            
            relation = {
                'source': resource_uri,
                'source_label': processor.get_label(resource_uri) or resource_uri.split('/')[-1],
                'relation': pred,
                'relation_type': pred_label,
                'target': obj,
                'target_label': obj_label if is_uri else obj,
                'is_uri_target': is_uri
            }
            relations.append(relation)
            
            # ì¬ê·€ì ìœ¼ë¡œ ê´€ê³„ íƒìƒ‰ (URIì¸ ê²½ìš°ì—ë§Œ)
            if is_uri and depth > 1:
                child_relations = self._build_relation_network(processor, obj, depth - 1, visited)
                relations.extend(child_relations)
        
        print(f"[DEBUG] ìµœì¢… ê´€ê³„ ìˆ˜: {len(relations)}")
        return relations
    
    def _analyze_keyword_search(self, request, processor):
        """í‚¤ì›Œë“œ ê²€ìƒ‰ ë° ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ë¶„ì„"""
        keyword = request.data.get('keyword')
        
        if not keyword:
            return Response({
                'error': 'ê²€ìƒ‰ í‚¤ì›Œë“œ(keyword)ê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }, status=status.HTTP_400_BAD_REQUEST)
        
        # ë¼ë²¨ì— í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¦¬ì†ŒìŠ¤ ê²€ìƒ‰
        query = f"""
        SELECT DISTINCT ?s ?label WHERE {{
            ?s <http://www.w3.org/2000/01/rdf-schema#label> ?label .
            FILTER(CONTAINS(LCASE(?label), "{keyword.lower()}"))
        }}
        """
        label_results = processor.execute_query(query)
        
        # ì†ì„± ê°’ì— í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¦¬ì†ŒìŠ¤ ê²€ìƒ‰
        query = f"""
        SELECT DISTINCT ?s ?p ?o WHERE {{
            ?s ?p ?o .
            FILTER(CONTAINS(LCASE(STR(?o)), "{keyword.lower()}"))
            FILTER(?p != <http://www.w3.org/2000/01/rdf-schema#label>)
            FILTER(ISURI(?s))
            FILTER(?p IS NOT NULL)
            FILTER(?o IS NOT NULL)
        }}
        """
        property_results = processor.execute_query(query)
        
        # ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬
        resources_by_label = []
        for result in label_results:
            resource_uri = result.get('s')
            label = result.get('label')
            
            # ë¦¬ì†ŒìŠ¤ ìœ í˜• ì¡°íšŒ
            resource_type = self._get_resource_type(processor, resource_uri)
            
            resources_by_label.append({
                'uri': resource_uri,
                'label': label,
                'type': resource_type,
                'match_type': 'label'
            })
        
        resources_by_property = {}
        for result in property_results:
            resource_uri = result.get('s')
            pred = result.get('p')
            value = result.get('o')
            
            if resource_uri not in resources_by_property:
                # ë¦¬ì†ŒìŠ¤ ë¼ë²¨ ì¡°íšŒ
                label = processor.get_label(resource_uri)
                # ë¦¬ì†ŒìŠ¤ ìœ í˜• ì¡°íšŒ
                resource_type = self._get_resource_type(processor, resource_uri)
                
                resources_by_property[resource_uri] = {
                    'uri': resource_uri,
                    'label': label,
                    'type': resource_type,
                    'match_type': 'property',
                    'matches': []
                }
            
            # ì†ì„± ë¼ë²¨ ì¡°íšŒ
            pred_label = processor.get_label(pred) or (pred.split('/')[-1] if pred else 'unknown')
            
            resources_by_property[resource_uri]['matches'].append({
                'property': pred,
                'property_label': pred_label,
                'value': value
            })
        
        # ê²°ê³¼ ë³‘í•© ë° ë°˜í™˜
        all_resources = list(resources_by_label)
        all_resources.extend(list(resources_by_property.values()))
        
        # ë¦¬ì†ŒìŠ¤ ìœ í˜•ë³„ ê·¸ë£¹í™”
        resource_groups = {}
        for resource in all_resources:
            # null ê°’ í™•ì¸ ë° ì²˜ë¦¬
            if resource.get('uri') is None:
                continue
                
            res_type = resource.get('type', 'ê¸°íƒ€')
            if res_type not in resource_groups:
                resource_groups[res_type] = []
            resource_groups[res_type].append(resource)
        
        return Response({
            'keyword': keyword,
            'total_results': len(all_resources),
            'label_matches': len(resources_by_label),
            'property_matches': len(resources_by_property),
            'resource_groups': resource_groups
        }, status=status.HTTP_200_OK)
    
    def _get_resource_type(self, processor, resource_uri):
        """ë¦¬ì†ŒìŠ¤ì˜ íƒ€ì…(í´ë˜ìŠ¤)ì„ ì¡°íšŒí•©ë‹ˆë‹¤."""
        query = f"""
        SELECT ?type ?type_label WHERE {{
            <{resource_uri}> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> ?type .
            OPTIONAL {{ ?type <http://www.w3.org/2000/01/rdf-schema#label> ?type_label }}
        }}
        """
        results = processor.execute_query(query)
        
        if results:
            type_uri = results[0].get('type')
            type_label = results[0].get('type_label')
            
            if type_label:
                return type_label
            elif type_uri:
                return type_uri.split('/')[-1]
        
        return 'ê¸°íƒ€'
    
    def _analyze_category_stats(self, request, processor):
        """ì¹´í…Œê³ ë¦¬(í´ë˜ìŠ¤)ë³„ í†µê³„ ë¶„ì„"""
        category = request.data.get('category')
        
        if not category:
            # ëª¨ë“  í´ë˜ìŠ¤ì˜ í†µê³„ ì œê³µ
            query = """
            SELECT ?type (COUNT(?s) as ?count) WHERE {
                ?s <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> ?type .
            }
            GROUP BY ?type
            ORDER BY DESC(?count)
            """
            results = processor.execute_query(query)
            
            category_stats = []
            for result in results:
                type_uri = result.get('type')
                count = result.get('count')
                
                # íƒ€ì… ë¼ë²¨ ì¡°íšŒ
                type_label = processor.get_label(type_uri) or type_uri.split('/')[-1]
                
                category_stats.append({
                    'uri': type_uri,
                    'label': type_label,
                    'count': count
                })
            
            return Response({
                'category_stats': category_stats,
                'total_categories': len(category_stats)
            }, status=status.HTTP_200_OK)
        else:
            # íŠ¹ì • í´ë˜ìŠ¤ì˜ í†µê³„ ì œê³µ
            # í•´ë‹¹ í´ë˜ìŠ¤ì˜ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ ê³„ì‚°
            query = f"""
            SELECT (COUNT(?s) as ?count) WHERE {{
                ?s <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <{category}> .
            }}
            """
            count_results = processor.execute_query(query)
            instance_count = count_results[0].get('count', 0) if count_results else 0
            
            # ì†ì„±ë³„ ì‚¬ìš© ë¹ˆë„ ê³„ì‚°
            query = f"""
            SELECT ?p (COUNT(?p) as ?count) WHERE {{
                ?s <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <{category}> .
                ?s ?p ?o .
                FILTER(?p != <http://www.w3.org/1999/02/22-rdf-syntax-ns#type>)
            }}
            GROUP BY ?p
            ORDER BY DESC(?count)
            """
            property_results = processor.execute_query(query)
            
            property_stats = []
            for result in property_results:
                prop_uri = result.get('p')
                count = result.get('count')
                
                # ì†ì„± ë¼ë²¨ ì¡°íšŒ
                prop_label = processor.get_label(prop_uri) or prop_uri.split('/')[-1]
                
                property_stats.append({
                    'uri': prop_uri,
                    'label': prop_label,
                    'count': count
                })
            
            # ì¹´í…Œê³ ë¦¬ ë¼ë²¨ ì¡°íšŒ
            category_label = processor.get_label(category) or category.split('/')[-1]
            
            return Response({
                'category_uri': category,
                'category_label': category_label,
                'instance_count': instance_count,
                'property_stats': property_stats
            }, status=status.HTTP_200_OK)
    
    def _analyze_resource_summary(self, request, processor):
        """ë¦¬ì†ŒìŠ¤ ì •ë³´ë¥¼ ìš”ì•½í•˜ì—¬ ì œê³µ"""
        resource_uri = request.data.get('resource_uri')
        
        if not resource_uri:
            return Response({
                'error': 'resource_uriê°€ í•„ìš”í•©ë‹ˆë‹¤.'
            }, status=status.HTTP_400_BAD_REQUEST)
        
        # ë¦¬ì†ŒìŠ¤ ê¸°ë³¸ ì •ë³´ ì¡°íšŒ
        resource_info = processor.get_resource_info(resource_uri)
        
        # ë¦¬ì†ŒìŠ¤ ë¼ë²¨ ì¡°íšŒ
        resource_label = processor.get_label(resource_uri) or resource_uri.split('/')[-1]
        
        # ë¦¬ì†ŒìŠ¤ íƒ€ì… ì¡°íšŒ
        resource_type = self._get_resource_type(processor, resource_uri)
        
        # ì¤‘ìš” ì†ì„± ë¶„ë¥˜ (ì˜ˆ: ì •ì˜, ì¦ìƒ, í•©ë³‘ì¦ ë“±)
        summary = {
            'uri': resource_uri,
            'label': resource_label,
            'type': resource_type,
            'definitions': [],
            'symptoms': [],
            'causes': [],
            'complications': [],
            'treatments': [],
            'related_resources': [],
            'other_properties': {}
        }
        
        # ì†ì„± ë¶„ë¥˜ ì§„í–‰
        for pred, values in resource_info.items():
            pred_label = processor.get_label(pred) or (pred.split('/')[-1] if pred else 'unknown')
            
            if values is None or len(values) == 0:
                continue
                
            # ì†ì„±ì— ë”°ë¼ ì ì ˆí•œ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜
            if 'definition' in pred.lower() or 'ì •ì˜' in pred_label:
                for value in values:
                    if value is not None:
                        summary['definitions'].append(value)
            elif 'symptom' in pred.lower() or 'ì¦ìƒ' in pred_label:
                for value in values:
                    if value is None:
                        continue
                    if isinstance(value, str) and value.startswith('http'):
                        # URIì¸ ê²½ìš° ë¼ë²¨ ì¡°íšŒ
                        value_label = processor.get_label(value)
                        summary['symptoms'].append({
                            'uri': value,
                            'label': value_label
                        })
                    else:
                        summary['symptoms'].append(value)
            elif 'cause' in pred.lower() or 'ì›ì¸' in pred_label:
                for value in values:
                    if isinstance(value, str) and value.startswith('http'):
                        value_label = processor.get_label(value)
                        summary['causes'].append({
                            'uri': value,
                            'label': value_label
                        })
                    else:
                        summary['causes'].append(value)
            elif 'complication' in pred.lower() or 'í•©ë³‘ì¦' in pred_label:
                for value in values:
                    if isinstance(value, str) and value.startswith('http'):
                        value_label = processor.get_label(value)
                        summary['complications'].append({
                            'uri': value,
                            'label': value_label
                        })
                    else:
                        summary['complications'].append(value)
            elif 'treatment' in pred.lower() or 'ì¹˜ë£Œ' in pred_label:
                for value in values:
                    if isinstance(value, str) and value.startswith('http'):
                        value_label = processor.get_label(value)
                        summary['treatments'].append({
                            'uri': value,
                            'label': value_label
                        })
                    else:
                        summary['treatments'].append(value)
            elif pred.endswith('label') or pred_label == 'label':
                # ì´ë¯¸ ë¼ë²¨ ì •ë³´ëŠ” ë”°ë¡œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ
                continue
            elif isinstance(values[0], str) and values[0].startswith('http'):
                # URIì¸ ê²½ìš° ê´€ë ¨ ë¦¬ì†ŒìŠ¤ë¡œ ë¶„ë¥˜
                for value in values:
                    value_label = processor.get_label(value)
                    summary['related_resources'].append({
                        'property': pred,
                        'property_label': pred_label,
                        'uri': value,
                        'label': value_label
                    })
            else:
                # ê·¸ ì™¸ ì†ì„±ì€ ê¸°íƒ€ ì†ì„±ìœ¼ë¡œ ë¶„ë¥˜
                summary['other_properties'][pred_label] = values
        
        # ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±
        summary_text = self._generate_summary_text(summary)
        
        # ê²°ê³¼ ë°˜í™˜
        return Response({
            'resource_uri': resource_uri,
            'resource_label': resource_label,
            'resource_type': resource_type,
            'summary': summary,
            'summary_text': summary_text
        }, status=status.HTTP_200_OK)
    
    def _generate_summary_text(self, summary):
        """ìš”ì•½ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìì—°ì–´ ìš”ì•½ í…ìŠ¤íŠ¸ ìƒì„±"""
        label = summary.get('label', '')
        type_label = summary.get('type', '')
        
        text_parts = [f"{label}ì€(ëŠ”) {type_label}ì…ë‹ˆë‹¤."]
        
        # ì •ì˜ ì¶”ê°€
        if summary.get('definitions'):
            text_parts.append(f"ì •ì˜: {summary['definitions'][0]}")
        
        # ì¦ìƒ ì¶”ê°€
        if summary.get('symptoms'):
            symptoms_text = []
            for symptom in summary['symptoms'][:5]:  # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ í‘œì‹œ
                if isinstance(symptom, dict):
                    symptoms_text.append(symptom.get('label', ''))
                else:
                    symptoms_text.append(symptom)
            
            if symptoms_text:
                text_parts.append(f"ì£¼ìš” ì¦ìƒ: {', '.join(symptoms_text)}")
        
        # ì›ì¸ ì¶”ê°€
        if summary.get('causes'):
            causes_text = []
            for cause in summary['causes'][:3]:  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ í‘œì‹œ
                if isinstance(cause, dict):
                    causes_text.append(cause.get('label', ''))
                else:
                    causes_text.append(cause)
            
            if causes_text:
                text_parts.append(f"ì›ì¸: {', '.join(causes_text)}")
        
        # í•©ë³‘ì¦ ì¶”ê°€
        if summary.get('complications'):
            complications_text = []
            for complication in summary['complications'][:3]:
                if isinstance(complication, dict):
                    complications_text.append(complication.get('label', ''))
                else:
                    complications_text.append(complication)
            
            if complications_text:
                text_parts.append(f"ê´€ë ¨ í•©ë³‘ì¦: {', '.join(complications_text)}")
        
        # ì¹˜ë£Œë²• ì¶”ê°€
        if summary.get('treatments'):
            treatments_text = []
            for treatment in summary['treatments'][:3]:
                if isinstance(treatment, dict):
                    treatments_text.append(treatment.get('label', ''))
                else:
                    treatments_text.append(treatment)
            
            if treatments_text:
                text_parts.append(f"ì¹˜ë£Œë²•: {', '.join(treatments_text)}")
        
        return " ".join(text_parts)
